{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LoRA Training on Dataset"
      ],
      "metadata": {
        "id": "4abM66JsSFpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Creating file paths and folders\n",
        "data_dir = \"lora_data\"\n",
        "metadata_path = os.path.join(data_dir, \"metadata.jsonl\")\n",
        "\n",
        "# custom captions mapped by filename, this requires custom annotations for the dataset\n",
        "captions = {\n",
        "    \"Chess Board 1.jpg\": \"an overhead view of a wooden chessboard with pieces in the middle game\",\n",
        "    \"Chess Board 2.jpg\": \"a high view of chessboard on glass table\",\n",
        "    \"Chess Board 3.jpg\": \"a wooden chess board on concrete floor in mid game\",\n",
        "    \"Chess Board 4.jpg\": \"a chessboard mid match on a wooden floor\",\n",
        "    \"Chess Board 5.jpg\": \"a black and white chess board over a dark wooden floor\",\n",
        "    \"Chess Board 6.jpg\": \"a brown chessboard viewed overhead with captured pieces on maple wood\",\n",
        "    \"Chess Board 7.jpg\": \"a chess match in progress with pieces spread across the board\",\n",
        "    \"Chess Board 8.jpg\": \"a 3D render of a glass chessboard under dramatic lighting\",\n",
        "    \"Chess Board 9.jpg\": \"a minimalist chessboard with modern abstract chess pieces\",\n",
        "    \"Chess Board 10.jpg\": \"a closeup of the final checkmate move on a chessboard under dramatic lighting\"\n",
        "}\n",
        "\n",
        "\n",
        "with open(metadata_path, \"w\") as f:\n",
        "    for filename in os.listdir(data_dir):\n",
        "        if filename in captions:\n",
        "            record = {\"file_name\": filename, \"text\": captions[filename]}\n",
        "            f.write(json.dumps(record) + \"\\n\")\n",
        "\n",
        "print(f\"metadata.jsonl with custom captions created at {metadata_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woUqLt1ER96L",
        "outputId": "c37a9dd2-83da-4baa-9612-448c473df3d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadata.jsonl with custom captions created at lora_data/metadata.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Installs required to using the current LoRA text to image model\n",
        "!pip uninstall -y diffusers\n",
        "!pip install -U git+https://github.com/huggingface/diffusers\n",
        "!pip install -U accelerate transformers safetensors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyaOtRwtJaez",
        "outputId": "64968d79-092d-4d84-a8a9-5bc1c052886f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: diffusers 0.35.1\n",
            "Uninstalling diffusers-0.35.1:\n",
            "  Successfully uninstalled diffusers-0.35.1\n",
            "Collecting git+https://github.com/huggingface/diffusers\n",
            "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-0sh5w_xi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-0sh5w_xi\n",
            "  Resolved https://github.com/huggingface/diffusers to commit 1066de8c699db994ecd6beadd7d5293ffc3ead49\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (3.19.1)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (0.35.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.36.0.dev0) (11.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers==0.36.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers==0.36.0.dev0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers==0.36.0.dev0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers==0.36.0.dev0) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->diffusers==0.36.0.dev0) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (6.0.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.34.0->diffusers==0.36.0.dev0) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers==0.36.0.dev0) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.36.0.dev0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.36.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->diffusers==0.36.0.dev0) (1.3.1)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.36.0.dev0-py3-none-any.whl size=4269879 sha256=c38f844e95d5b72185d0c46e3c99fced132b4425bc5ce0f0581315dc15910ca6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gnvux61k/wheels/90/d4/44/a58bc00fb405fefb633b0d9d2307f6e3aec6cc1775d82555d3\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.36.0.dev0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "Successfully installed transformers-4.57.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cloning the github for LoRA\n",
        "!git clone https://github.com/huggingface/diffusers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKw8rxsMLTt2",
        "outputId": "ed32edaf-9da1-42f7-bd8f-ea140276aa8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 105602, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 105602 (delta 77), reused 46 (delta 45), pack-reused 105509 (from 3)\u001b[K\n",
            "Receiving objects: 100% (105602/105602), 78.76 MiB | 11.75 MiB/s, done.\n",
            "Resolving deltas: 100% (78326/78326), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Runnning the CLI to obtain weights from fine tuning\n",
        "!accelerate launch \\\n",
        "  diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 \\\n",
        "  --train_data_dir=lora_data \\\n",
        "  --output_dir=lora_weights \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --max_train_steps=500 \\\n",
        "  --mixed_precision=fp16\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh8uGZJrYH89",
        "outputId": "fa1a0d01-e0f2-478e-ee20-c9899beb88da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-10-07 16:37:40.504743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759855060.524901    2313 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759855060.530968    2313 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759855060.546571    2313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759855060.546600    2313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759855060.546604    2313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759855060.546609    2313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-07 16:37:40.551346: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "INFO:__main__:Distributed environment: DistributedType.NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "scheduler_config.json: 100% 308/308 [00:00<00:00, 2.14MB/s]\n",
            "{'prediction_type', 'sample_max_value', 'clip_sample_range', 'dynamic_thresholding_ratio', 'timestep_spacing', 'rescale_betas_zero_snr', 'thresholding', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "tokenizer_config.json: 100% 806/806 [00:00<00:00, 5.57MB/s]\n",
            "vocab.json: 1.06MB [00:00, 113MB/s]\n",
            "merges.txt: 525kB [00:00, 143MB/s]\n",
            "special_tokens_map.json: 100% 472/472 [00:00<00:00, 4.82MB/s]\n",
            "config.json: 100% 617/617 [00:00<00:00, 4.66MB/s]\n",
            "text_encoder/model.safetensors: 100% 492M/492M [00:06<00:00, 70.8MB/s]\n",
            "config.json: 100% 547/547 [00:00<00:00, 4.43MB/s]\n",
            "vae/diffusion_pytorch_model.safetensors: 100% 335M/335M [00:04<00:00, 73.2MB/s]\n",
            "{'use_quant_conv', 'latents_std', 'latents_mean', 'force_upcast', 'use_post_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'shift_factor'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "config.json: 100% 743/743 [00:00<00:00, 7.25MB/s]\n",
            "unet/diffusion_pytorch_model.safetensors: 100% 3.44G/3.44G [02:17<00:00, 24.9MB/s]\n",
            "{'class_embeddings_concat', 'conv_in_kernel', 'resnet_out_scale_factor', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'encoder_hid_dim_type', 'projection_class_embeddings_input_dim', 'num_class_embeds', 'time_embedding_type', 'cross_attention_norm', 'dropout', 'only_cross_attention', 'mid_block_only_cross_attention', 'transformer_layers_per_block', 'time_embedding_dim', 'addition_embed_type', 'timestep_post_act', 'resnet_time_scale_shift', 'class_embed_type', 'encoder_hid_dim', 'reverse_transformer_layers_per_block', 'addition_time_embed_dim', 'mid_block_type', 'resnet_skip_time_act', 'use_linear_projection', 'num_attention_heads', 'upcast_attention', 'conv_out_kernel', 'time_cond_proj_dim', 'dual_cross_attention', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "Generating train split: 10 examples [00:00, 282.52 examples/s]\n",
            "INFO:__main__:***** Running training *****\n",
            "INFO:__main__:  Num examples = 10\n",
            "INFO:__main__:  Num Epochs = 167\n",
            "INFO:__main__:  Instantaneous batch size per device = 1\n",
            "INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "INFO:__main__:  Gradient Accumulation steps = 4\n",
            "INFO:__main__:  Total optimization steps = 500\n",
            "Steps: 100% 500/500 [10:14<00:00,  1.31s/it, lr=0.0001, step_loss=0.157]INFO:accelerate.accelerator:Saving current state to lora_weights/checkpoint-500\n",
            "INFO:accelerate.checkpointing:Model weights saved in lora_weights/checkpoint-500/model.safetensors\n",
            "INFO:accelerate.checkpointing:Optimizer state saved in lora_weights/checkpoint-500/optimizer.bin\n",
            "INFO:accelerate.checkpointing:Scheduler state saved in lora_weights/checkpoint-500/scheduler.bin\n",
            "INFO:accelerate.checkpointing:Sampler state for dataloader 0 saved in lora_weights/checkpoint-500/sampler.bin\n",
            "INFO:accelerate.checkpointing:Gradient scaler state saved in lora_weights/checkpoint-500/scaler.pt\n",
            "INFO:accelerate.checkpointing:Random states saved in lora_weights/checkpoint-500/random_states_0.pkl\n",
            "Model weights saved in lora_weights/checkpoint-500/pytorch_lora_weights.safetensors\n",
            "INFO:__main__:Saved state to lora_weights/checkpoint-500\n",
            "Steps: 100% 500/500 [10:30<00:00,  1.31s/it, lr=0.0001, step_loss=0.0113]Model weights saved in lora_weights/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 500/500 [10:30<00:00,  1.26s/it, lr=0.0001, step_loss=0.0113]\n"
          ]
        }
      ]
    }
  ]
}